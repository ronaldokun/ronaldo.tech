{
  
    
        "post0": {
            "title": "Leitura de dados bin√°rios comprimidos - um exemplo de otimiza√ß√£o gradual em Python",
            "content": ". O objeto desse artigo s√£o arquivos bin√°rios com extens√£o .bin - gerados pela aplica√ß√£o Logger embarcada nas esta√ß√µes de monitoramento do tipo Rfeye Node 20-6. . Estes arquivos armazenam diversos metadados sobre a medi√ß√£o e blocos com informa√ß√£o num√©rica, que s√£o as medidas em si, chamadas aqui de dados de espectro ou dados espectrais ou dados de n√≠vel. . A vers√£o recente da aplica√ß√£o Logger gera dados comprimidos de maneira muito eficiente, o que torna a descompress√£o desafiadora para arquivos com muitos dados e bastante demorada caso seja feita de maneira &quot;ing√™nua&quot;. . Mesmo que o problema apresentado aqui pare√ßa obscuro, as t√©cnicas de otimiza√ß√£o podem ser aplicadas em outros contextos que sejam relevantes para quem l√™. . . Note: Nos par√°grafos a seguir irei passar por cima deliberadamente ( por n√£o serem relevantes para a otimiza√ß√£o e por pouco conhecimento no assunto ) de explica√ß√µes sobre a parte de f√≠sica / engenharia de telecomunica√ß√µes e irei focar mais no problema espec√≠fico de decodifica√ß√£o dos arquivos. . Bibliotecas necess&#225;rias . !pip3 install rfpye line_profiler fastprogress -qUU . Baixando arquivos bin&#225;rios . Como primeiro passos precisamos de alguns tipos de arquivos bin√°rios como exemplo: Neste reposit√≥rio √© disponibilizado diversos tipos de Arquivos de Espectro: https://github.com/EricMagalhaesDelgado/SpecFiles . Para nossos prop√≥sitos queremos um arquivo comprimido, cujo nome cont√©m MaskBroken . !wget &#39;https://drive.google.com/u/2/uc?id=1K-riwTKeP6HuUtnRFuN2wxjRrdRxApdu&amp;export=download&#39; --output-document &#39;rfeye002092_210223_T163131_MaskBroken.bin&#39; . --2021-09-20 03:16:45-- https://drive.google.com/u/2/uc?id=1K-riwTKeP6HuUtnRFuN2wxjRrdRxApdu&amp;export=download Resolving drive.google.com (drive.google.com)... 64.233.189.101, 64.233.189.139, 64.233.189.102, ... Connecting to drive.google.com (drive.google.com)|64.233.189.101|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-0g-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/a228g2dpkhdrm9ipevs8oojmqa58dplb/1632107775000/01599860855598048438/*/1K-riwTKeP6HuUtnRFuN2wxjRrdRxApdu?e=download [following] Warning: wildcards not supported in HTTP. --2021-09-20 03:16:47-- https://doc-0g-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/a228g2dpkhdrm9ipevs8oojmqa58dplb/1632107775000/01599860855598048438/*/1K-riwTKeP6HuUtnRFuN2wxjRrdRxApdu?e=download Resolving doc-0g-00-docs.googleusercontent.com (doc-0g-00-docs.googleusercontent.com)... 74.125.23.132, 2404:6800:4008:c02::84 Connecting to doc-0g-00-docs.googleusercontent.com (doc-0g-00-docs.googleusercontent.com)|74.125.23.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/octet-stream] Saving to: ‚Äòrfeye002092_210223_T163131_MaskBroken.bin‚Äô rfeye002092_210223_ [ &lt;=&gt; ] 95.37M 193MB/s in 0.5s 2021-09-20 03:16:48 (193 MB/s) - ‚Äòrfeye002092_210223_T163131_MaskBroken.bin‚Äô saved [100000736] . Explorando o arquivo .bin . Cada arquivo .bin possui dados distintos em um mesmo arquivo, em dois n√≠veis blocos e thread_id. . Um bloco determina o tipo de dado: espectro, gps, dados textuais etc... | O thread_id nada mais √© que um identificador da faixa espec√≠fica de varredura armazenada naquele bloco. | . A fun√ß√£o a seguir parse_bin encapsula a leitura do arquivo e seus metadados e retorna um dicion√°rio cujas chaves s√£o as diferentes combina√ß√µes de blocos e thread_id e os valores s√£o listas com os blocos. . Note: Cada bloco √© uma classe python contendo seus atributos. Os detalhes de implementa√ß√£o dessa fun√ß√£o podem ser ignorados, o que nos interessa aqui √© uma vez que temos os bytes de dados com os valores de n√≠veis como o lemos de maneira eficiente para ponto flutuante. . Tip: A biblioteca rfpye criada para o processamento desses arquivos faz amplo uso da biblioteca fastcore. Esta expande as funcionalidades da linguagem python inspirada em atributos muito √∫teis de outras linguagens. Recomendo fortemente para quem deseja expandir o seu invent√°rio de ferramentas python . %load_ext line_profiler . import os from tqdm.notebook import tqdm from time import sleep from fastcore.xtras import Path import gc import warnings with warnings.catch_warnings(): warnings.simplefilter(&quot;ignore&quot;) from rfpye.parser import parse_bin from rfpye.utils import public_attrs from fastcore.foundation import L import numpy as np import pandas as pd from rich import print from IPython.display import display . blocks = parse_bin(&#39;rfeye002092_210223_T163131_MaskBroken.bin&#39;) blocks = blocks[&#39;blocks&#39;] for k,v in blocks.items(): print(f&#39;Tipo de Bloco: {k[0]}, Thread_ID: {k[1]}, N¬∫ de blocos {len(v)}, Exemplo de Blocos: {v[0]}&#39;) . Tipo de Bloco: 21, Thread_ID: 0, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType21 object at 0x7f1f7f285390&gt; . Tipo de Bloco: 42, Thread_ID: 0, N¬∫ de blocos 2, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7fb72210&gt; . Tipo de Bloco: 42, Thread_ID: 301, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838e4d0&gt; . Tipo de Bloco: 42, Thread_ID: 311, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838e550&gt; . Tipo de Bloco: 42, Thread_ID: 321, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838e610&gt; . Tipo de Bloco: 42, Thread_ID: 331, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838e6d0&gt; . Tipo de Bloco: 68, Thread_ID: 331, N¬∫ de blocos 734, Exemplo de Blocos: &lt;rfpye.blocks.DType68 object at 0x7f1f7838e790&gt; . Tipo de Bloco: 42, Thread_ID: 341, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838ea90&gt; . Tipo de Bloco: 42, Thread_ID: 351, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838eb50&gt; . Tipo de Bloco: 42, Thread_ID: 361, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838ec10&gt; . Tipo de Bloco: 42, Thread_ID: 371, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838ecd0&gt; . Tipo de Bloco: 42, Thread_ID: 381, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838ed90&gt; . Tipo de Bloco: 42, Thread_ID: 391, N¬∫ de blocos 1, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f7838ee50&gt; . Tipo de Bloco: 68, Thread_ID: 301, N¬∫ de blocos 133932, Exemplo de Blocos: &lt;rfpye.blocks.DType68 object at 0x7f1f7838ef10&gt; . Tipo de Bloco: 68, Thread_ID: 311, N¬∫ de blocos 11464, Exemplo de Blocos: &lt;rfpye.blocks.DType68 object at 0x7f1f77c1e890&gt; . Tipo de Bloco: 40, Thread_ID: 1, N¬∫ de blocos 18462, Exemplo de Blocos: &lt;rfpye.blocks.DType40 object at 0x7f1f77c20210&gt; . Tipo de Bloco: 42, Thread_ID: 1, N¬∫ de blocos 307, Exemplo de Blocos: &lt;rfpye.blocks.DType42 object at 0x7f1f77b1b390&gt; . Tipo de Bloco: 68, Thread_ID: 341, N¬∫ de blocos 44, Exemplo de Blocos: &lt;rfpye.blocks.DType68 object at 0x7f1f7704ffd0&gt; . Tipo de Bloco: 68, Thread_ID: 321, N¬∫ de blocos 46, Exemplo de Blocos: &lt;rfpye.blocks.DType68 object at 0x7f1f73715110&gt; . Vemos que esse arquivo tem diferentes tipos de blocos, um bloco nada mais √© que uma classe python que armazenada os atributos do bloco. . O que nos interessa aqui s√£o os blocos de espectro, blocos do tipo 68. . Temos 5 diferentes blocos do tipo 68, vamos observar o que os diferencia: . b301 = blocks[(68,301)][0] b321 = blocks[(68,321)][0] b331 = blocks[(68,331)][0] b341 = blocks[(68,341)][0] . print(f&#39;Frequ√™ncia Inicial (MHz) :{b301.start_mega}, Frequ√™ncia Final (MHz) {b301.stop_mega}&#39;) . Frequ√™ncia Inicial (MHz) :108, Frequ√™ncia Final (MHz) 137 . print(f&#39;Frequ√™ncia Inicial (MHz) :{b321.start_mega}, Frequ√™ncia Final (MHz) {b321.stop_mega}&#39;) . Frequ√™ncia Inicial (MHz) :320, Frequ√™ncia Final (MHz) 340 . print(f&#39;Frequ√™ncia Inicial (MHz) :{b331.start_mega}, Frequ√™ncia Final (MHz) {b331.stop_mega}&#39;) . Frequ√™ncia Inicial (MHz) :400, Frequ√™ncia Final (MHz) 410 . print(f&#39;Frequ√™ncia Inicial (MHz) :{b341.start_mega}, Frequ√™ncia Final (MHz) {b341.stop_mega}&#39;) . Frequ√™ncia Inicial (MHz) :960, Frequ√™ncia Final (MHz) 1219 . Vemos portanto que o qu√™ diferencia diferentes blocos do mesmo tipo mas com diferentes thread_id √© a faixa de frequ√™ncia de varredura. . O primeiro tipo de bloco mostrado, o bloco do tipo 68 e thread_id 301, √© o mais numeroso do arquivo com 133932 blocos. . A faixa desse arquivo √© muito importante e de grande enfoque nas monitora√ß√µes da Anatel - 108MHz a 137MHz. Essa faixa √© a do Servi√ßo Limitado M√≥vel Aeron√°utico, dedicada a comunica√ß√µes entre aeronaves com as torres de comando e entre si. . Cada bloco √© uma medi√ß√£o num intervalo de tempo espec√≠fico dessa faixa, no caso 108MHz a 137MHz, dividida em v√°rias amostras ( recortes ) da faixa. Portanto temos 133932 medi√ß√µes. . print(b301.data[b301.start:b301.stop]) . b&#39; xff xfaF xff xfaH xff xfaH xff xfaE xff xfaA xff xfaB xff xfaA xff xfa&gt; xff xfa&gt; xff xfa= xff xfa&lt; xff xfa; xff xfa; xff xfa; xff xfa; xff xfa; xff xfa5 xff xfa5 xff xfa6 xff xfa7 xff xfa8 xff xfa7 xff xfa6 xff xfa4 xffv`d` xff xfa6 xff x9bamm` xff xfa6 xff xfa8 xff xfa8 xff xfa8 xff xfa8 xff xfa7 xff xfa6 xff xfa5 xff x8ba xff xfa4 xff xfa6 xff xfa4 xff xfa5 xff xfa 5 xff x97g| x82{f xff xfa5 xff xfa5 xff xfa7 xff xfa7 xff xfa8 xff xfa6 xff xfa6 xff xfa6 xff xfa8 xff xfa7 xff xfa8 xff xfa8 xff xfa9 xff xfa&lt; xff xfa&gt; xff xfa&gt; xff xfaA xff xfaAB x00 x 00&#39; . O Atributo data s√£o os bytes brutos, i.e. n√£o decodificados. Os atributos start e stop recortam os bytes nos pontos correspondentes √†s medidas de n√≠vel do arquivo bin√°rio, os demais pontos do arquivo, os metadados, s√£o decodificados como atributos da classe, um exemplo foi mostrado acima com os atributos start_mega e stop_mega. . O restante desse artigo √© dedicado a decodifica√ß√£o dessas medidas de n√≠vel. . Codifica&#231;&#227;o Espectral . Dada esta√ß√£o faz uma medi√ß√£o de pot√™ncia, para dada frequ√™ncia, em dBm ( l√™-se &#39;de-b√™-eme&#39; ), uma escala logar√≠tmica com valores tipicamente negativos. A escala de valores que a esta√ß√£o armazena √© a seguinte Intervalo = [offset - 127.5, offset], onde offset (deslocamento) √© um valor pr√©-estabelecido. Se a medida estiver fora desse intervalo, os valores s√£o truncados. Um t√≠pico valor de offset √© -20dBm . Assim tendo o valor medido d em dBm ele √© codificado e salvo no arquivo como um valor b: . $$b = 2(d - offset) + 255$$ . Ao inserir os valores extremos do intervalo acima nessa f√≥rmula: . Para d = offset - 127.5: . $$ therefore b = 2[(offset - 127.5) - offset] + 255 = 2 (-127.5) + 255 implies b = 0$$ . Para d = offset: $$ therefore b = 2(offset - offset) + 255 = 2 * 0 + 255 implies b = 255$$ . Portanto o intervalo de valores poss√≠veis ao serem codificados com a f√≥rmula acima √© [0,255], justamente o intervalo de valores poss√≠veis em 8 bits ou 1 byte, sem sinal. Assim, os dados de espectro truncados e codificados dessa maneira permitem um armazenamento extremamente econ√¥mico, ocupando somente 1 byte (uint8 em python ou unsigned char na linguagem C.) . Para decodificar tal valor, basta fazer o procedimento inverso da f√≥rmula acima. Ao isolar o valor d temos: $$d = frac{b}{2} + offset - 127.5$$ . Compress&#227;o de Dados . Como dados de espectro s√£o extremamente ruidosos ( √≠ndice sinal-ru√≠do muito baixo ), isto √©, a maioria do que observamos numa dada &quot;janela&quot; do espectro √© simplesmente ru√≠do, a aplica√ß√£o Logger comprime esses dados de maneira engenhosa. Como mencionado, a cada instante de tempo a esta√ß√£o faz a medi√ß√£o dos n√≠veis de determinada faixa, para tal ela divide a faixa em diversos intervalos e mede o n√≠vel da frequ√™ncia central daquele intervalo. Quanto maior o n√∫mero de intervalos mais granulosa ou detalhada ser√£o essas medidas. . Algoritmo de Compress√£o . No script √© definido um limiar threshold, abaixo do qual tudo √© considerado ru√≠do | Para cada intervalo medido i, √© verificado se o valor est√° abaixo do limiar | Caso afirmativo esse processo se repete para os intervalos vizinhos i+1, i+2, etc... | Esses intervalos s√£o contados, at√© que apare√ßa um ponto acima do limiar ou o m√°ximo de 250 pontos seja atingido Nesse ponto √© gravado no arquivo um byte marcador RUN=255 indicando que o pr√≥ximo byte armazena a contagem de pontos abaixo do limiar | Nesse procedimento √© ocupado somente 2 bytes, podendo ter sido comprimido o limite de 250 bytes no melhor dos casos. | . | . Um problema que pode ocorrer no algoritmo acima √© se nos dados de medi√ß√£o tivermos o valor m√°ximo medido d=offset assim o valor a ser gravado ser√° b=255, o mesmo valor usado como marcador. . Nesses casos temos o valor literal no ponto e n√£o queremos que isso seja interpretado como marcador. . Para lidar com esse caso √© definido um segundo marcador ESC=254, esse marcador informa o algoritmo de decodifica√ß√£o que a medida seguinte √© literal e n√£o se trata de um marcador. Esse marcador tamb√©m √© utilizado para realizar escape dele mesmo, isto √©, quando a medida codificada √© exatamente igual a b=254, isso ocorre quando o valor medido √©: d=offset - 0.5. Para verificar basta substituir esse valor na f√≥rmula acima. . Com alguns exemplos a seguir ficar√° mais claro o funcionamento do algoritmo. O algoritmo original de codifica√ß√£o ( escrito em C ) √© apresentado a seguir: . int run_length_encode(unsigned char *dest, unsigned char *src, int nsrc, int thresh) { unsigned char ib; int di = 0, si, nunder = 0; for(si = 0; si &lt; nsrc; si++){ ib = src[si]; if ((ib &lt; thresh) &amp;&amp; (si &lt; (nsrc-1)) &amp;&amp; (nunder &lt; 250)) { nunder += 1; } else { if (nunder &gt; 0) { dest[di++] = RUN; dest[di++] = nunder; nunder = 0; } if ((ib == RUN) || (ib == ESC)) { dest[di++] = ESC; dest[di++] = ib; } else { dest[di++] = ib; } } } return di; } . O algoritmo √© bastante leg√≠vel mesmo para quem n√£o conhece C, exceto talvez por algumas coisas estranhas como ponteiros * e a incrementa√ß√£o de vari√°veis dentro dos arrays. Vamos escrev√™-lo em python sem alterar sua estrutura em C mas colocando nomes das vari√°veis mais amig√°veis e comentando para decifrarmos melhor seu prop√≥sito. . RUN = 255 ESC = 254 def run_length_encode(destino, origem, n_origem, limiar): conta_origem, conta_destino = 0,0 # si, and di num_under = 0 for si in range(n_origem): # percorro as posi√ß√µes do arquivo de origem byte_atual = origem[si] # leio o byte do arquivo fonte correspondente √† posi√ß√£o si # Se o byte est√° abaixo do limiar e n√£o atingi o fim do arquivo ou a contagem m√°xima if (byte_atual &lt; limiar) and (si &lt; n_origem - 1) and (num_under &lt; 250): num_under += 1 # incremento o contador de valor abaixo do limiar else: if num_under &gt; 0: # valor atual est√° acima do limiar mas at√© o momento est√°vamos contando valores abaixo do limiar destination[conta_destino] = RUN # insiro o marcador de contagem de valores abaixo do limiar na posi√ß√£o atual do arquivo de destino conta_destino += 1 # incremento o contador do arquivo de destino destination[conta_destino] = num_under # coloco a contagem em si na pr√≥xima posi√ß√£o conta_destino += 1 # incremento o contador do arquivo de destino num_under = 0 # zero o contador de valores abaixo do limiar if (byte_atual == RUN) or (byte_atual == ESC): # checo se o valor lido atual corresponde a um dos valores utilizados como marcador destination[conta_destino] = ESC # coloco o marcador que o valor a seguir lido √© literal conta_destino += 1 # incremento o contador do arquivo de destino destination[conta_destino] = byte_atual conta_destino += 1 # incremento o contador do arquivo de destino else: # caso o valor medido n√£o corresponda a um dos valores reservador de marcador eu simplesmente guardo esse valor na posi√ß√£o atual destination[conta_destino] = byte_atual conta_destino += 1 # incremento o contador do arquivo de destino return destination . O algoritmo est√° propositalmente &quot;n√£o-pyth√¥nico&quot;, mais ao estilo de C para ficar o mais pr√≥ximo do original e espa√ßado por conta dos v√°rios coment√°rios. . Como sempre as coisas ficam mais claras com alguns exemplos . Exemplo 1 - Somente valores abaixo do limiar, i.e. somente ru√≠do . destination = [0] * 10 #lista com 10 valores 0 offset = -20 limiar = -80 medidas = [-100] * 10 #lista com 10 valores com n√≠vel -100 . Como vimos acima esses valores de medida antes de serem codificados s√£o transformados com seguinte f√≥rmula: $b = 2(d - offset) + 255$. . Portanto para as medidas acima, nosso arquivo de origem gravado fica: . origem = [int(2 * (d - offset) + 255) for d in medidas] ; origem . [95, 95, 95, 95, 95, 95, 95, 95, 95, 95] . limiar_encoded = 2 * (limiar - offset) + 255 . run_length_encode(destination, origem, len(origem), limiar_encoded) . [255, 9, 95, 0, 0, 0, 0, 0, 0, 0] . Temos 10 valores, todos abaixo do limiar, ent√£o o algoritmo armazena o marcador RUN=255 mais a contagem de valores a seguir. Era esperado que a contagem fosse 10 e n√£o 9. No entanto pela implementa√ß√£o do algoritmo o √∫ltimo valor, 95, √© armazenado literalmente, mesmo estando abaixo do limiar. Esse √© um caso limite no qual todos os valores do espectro est√£o abaixo do limiar. Perceba que nesse caso limite 3 bytes foram ocupados dos 10 originais . Exemplo 2 - Ru√≠do mais valores normais . destination = [0] * 10 #lista com 10 valores 0 offset = -20 limiar = -80 medidas = [-100, -100, -100, -100, -100, -75, -62, -22, -30, -78] origem = [int(2 * (d - offset) + 255) for d in medidas] limiar_encoded = 2 * (limiar - offset) + 255 origem . [95, 95, 95, 95, 95, 145, 171, 251, 235, 139] . run_length_encode(destination, origem, len(origem), limiar_encoded) . [255, 5, 145, 171, 251, 235, 139, 0, 0, 0] . Temos 5 valores abaixo do limiar ent√£o √© armazenado o marcador RUN=255 seguido da contagem [255,5...] e em seguida s√£o armazenados os valores literais que est√£o acima do limiar. Para esse caso foram ocupados 7 dos 10 bytes originais, os valores 0 ao final mostram bytes que n√£o foram ocupados. . Exemplo 3 - Ru√≠do, Valores Normais e valores extremos igual ao offset . destination = [0] * 10 #lista com 10 valores 0 offset = -20 limiar = -80 medidas = [-100, -100, -100, -100, -100, -20, -20.5, -22, -30, -78] origem = [int(2 * (d - offset) + 255) for d in medidas] limiar_encoded = 2 * (limiar - offset) + 255 origem . [95, 95, 95, 95, 95, 255, 254, 251, 235, 139] . run_length_encode(destination, origem, len(origem), limiar_encoded) . [255, 5, 254, 255, 254, 254, 251, 235, 139, 0] . Os valores medidos igual ou pr√≥ximos ao offset -20, -20.5 ao serem transformados viram 255 e 254, os valores utilizados como marcador. Nesse caso teremos duas sinaliza√ß√µes de valor literal com o marcador ESC=254. . [255,5...] temos 5 valores abaixo do limiar | [...254,255...] temos o valor literal 255 e n√£o o marcador RUN | [...254,254...] temos o valor literal 254 e n√£o o marcador ESC | [...251,235,139] valores de medi√ß√£o literal | . Nesse caso economizamos somente 1 byte, denotado pelo valor 0 ao final da lista. Esses exemplos com poucos valores n√£o fazem jus ao algoritmo, o poder de compress√£o aparece quando temos milhares de dados como veremos a seguir. . Algoritmo de Descompress√£o . O Algoritmo de descompress√£o original em C √© mostrado a seguir: . #define RUN 255 #define ESC 254 int run_length_decode(unsigned char *dest, unsigned char *src, int nsrc, int thresh) { int si=0,di=0,nrun; unsigned char ib; while (si &lt; nsrc) { ib = src[si++]; if (ib == RUN) { nrun = src[si++]; while(nrun-- &gt;0){ dest[di++] = thresh; } } else if (ib == ESC) { /* next value is literal */ dest[di++] = src[si++]; } else { /* value */ dest[di++] = ib; } } return di; } . Vamos escrev√™-lo em python. . def run_length_decode(src, nsrc, thresh, offset): dest = [] # creates an empty destination list si = 0 #counter source di = 0 #counter destination while si &lt; nsrc: #while we didn&#39;t read the whole file ib = src[si] # read current position si+=1 # counter go to the next position if ib == RUN: # if current position is equal to marker RUN nrun = src[si] # next position indicates number of points below thresh si+=1 while nrun &gt; 0: dest.append(thresh) # we keep thresh in the destination nrun times di+=1 nrun-=1 elif ib == ESC: # next value is literal dest.append(src[di]/2 + offset - 127.5) di+=1 ; si+=1 else: # value dest.append(ib/2 + offset - 127.5) # If there isn&#39;t a marker I&#39;ll just keep the current value di+=1 return dest . O algoritmo basicamente faz: . Percorre o arquivo codificado fonte e l√™ byte a byte | Se o byte √© igual ao marcador RUN=255 √© sabido que o byte seguinte armazena a contagem de quantas vezes foi medido um valor abaixo do limiar | Um loop com essa contagem √© efetuado e a cada rodada √© armazenado o valor do limiar na lista de destino | Caso seja identificado o outro marcador ESC=254 √© armazenado o valor seguinte literal | Caso nenhum dos casos anteriores ocorra simplesmente √© armazenado o valor atual | . Teste de Velocidade do Algoritmo Original . A motiva√ß√£o para a otimiza√ß√£o da leitura desses arquivos comprimidos foi por conta de arquivos da ordem de 100MB, que ao serem descomprimidos geram por volta de 8GB de dados. Utilizamos um desses arquivos como exemplo. . Eu li e ouvi mais de uma vez que n√£o se faz otimiza√ß√£o sem &quot;profiling&quot;, isto √©, n√£o comece a otimizar as coisas antes de saber exatamente o qu√™ toma o tempo do seu c√≥digo. . Para nos ajudar nisso vamos usar a extens√£o da biblioteca line_profiler que mostra a execu√ß√£o linha a linha de dada fun√ß√£o que passarmos como argumento. . compressed_blocks = blocks[(68,301)] . RUN = 255 ESC = 254 . A fun√ß√£o a seguir testa o algoritmo original acima. . def test_orig(blocks, debug=False): decoded = [] if debug: blocks = blocks[:1] for block in progress_bar(blocks): src = block.data[block.start:block.stop] nsrc = len(src) thresh = block.thresh offset = block.offset decoded_value = run_length_decode(src, nsrc, thresh, offset) decoded.append(decoded_value) # Quase 2 bilh√µes de pontos numa lista ir√° ocupar quase 16GB de mem√≥ria! return decoded . Vamos checar o perfil de uma chamada da fun√ß√£o run_length_decode, isso √© alcan√ßado chamando a fun√ß√£o acima com o argumento debug=True. Assim executamos somente 1 bloco em vez de 133932. . %lprun -f run_length_decode test_orig(compressed_blocks, debug=True) . . 100.00% [1/1 00:00&lt;00:00] Timer unit: 1e-06 s Total time: 0.032464 s File: &lt;ipython-input-27-0e35b2a102ae&gt; Function: run_length_decode at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def run_length_decode(src, nsrc, thresh, offset): 2 1 4.0 4.0 0.0 dest = [] # creates an empty destination list 3 1 1.0 1.0 0.0 si = 0 #counter source 4 1 0.0 0.0 0.0 di = 0 #counter destination 5 133 70.0 0.5 0.2 while si &lt; nsrc: #while we didn&#39;t read the whole file 6 132 65.0 0.5 0.2 ib = src[si] # read current position 7 132 52.0 0.4 0.2 si+=1 # counter go to the next position 8 132 80.0 0.6 0.2 if ib == RUN: # if current position is equal to marker RUN 9 60 20.0 0.3 0.1 nrun = src[si] # next position indicates number of points below thresh 10 60 22.0 0.4 0.1 si+=1 11 14623 7302.0 0.5 22.5 while nrun &gt; 0: 12 14563 8522.0 0.6 26.3 dest.append(thresh) # we keep thresh in the destination nrun times 13 14563 7744.0 0.5 23.9 di+=1 14 14563 8428.0 0.6 26.0 nrun-=1 15 72 33.0 0.5 0.1 elif ib == ESC: # next value is literal 16 dest.append(src[di]/2 + offset - 127.5) 17 di+=1 ; si+=1 18 else: 19 # value 20 72 74.0 1.0 0.2 dest.append(ib/2 + offset - 127.5) # If there isn&#39;t a marker I&#39;ll just keep the current value 21 72 46.0 0.6 0.1 di+=1 22 1 1.0 1.0 0.0 return dest . Vemos que 98.7% do tempo a fun√ß√£o passa somente no loop while interno, linhas 11 a 14. Vamos ver o que isso significa para 133932 blocos. . . Warning: A fun√ß√£o run_length_decode decodifica quase 2 bilh√µes de pontos float64 e os retorna numa lista, isso ocupa em torno de 16GB de mem√≥ria A c√©lula a seguir armazena a quantidade de mem√≥ria f√≠sica presenta na inst√¢ncia rodando o c√≥digo, ent√£o √© checado primeiramente se existe dispon√≠vel mais de 16GB na m√°quina, do contr√°rio a c√©lula n√£o √© executada. . Caso voc√™ n√£o tenha tanta mem√≥ria dispon√≠vel assim mas queira executar a fun√ß√£o, basta comentar a parte na qual a lista √© armazenada: decoded.append e retire o if abaixo. . mem_bytes = os.sysconf(&#39;SC_PAGE_SIZE&#39;) * os.sysconf(&#39;SC_PHYS_PAGES&#39;) mem_gib = mem_bytes/(1024.**3) . %%time if mem_gib &gt; 16: d = test_orig(compressed_blocks) . . 100.00% [133932/133932 06:25&lt;00:00] CPU times: user 6min 11s, sys: 15.4 s, total: 6min 26s Wall time: 6min 25s . print(f&#39;N√∫mero de pontos: {len(d) * len(d[0])}&#39;) print(f&#39;Espa√ßo ocupado em mem√≥ria (GB): {(len(d) * len(d[0]) * 8)/(1024.**3):.2f}&#39;) . N√∫mero de pontos: 1960094820 . Espa√ßo ocupado em mem√≥ria (GB): 14.60 . Essa matriz de quase 2 bilh√µes de pontos float64, cada um ocupando 8 bytes, ocupa quase 15GB de mem√≥ria. . del d gc.collect() . 118 . Eliminar Loop while . Vemos que o loop while acima simplesmente adiciona o mesmo valor thresh por nrun vezes. . Note: Em python, n√£o precisamos adicionar o mesmo valor n vezes numa lista, um por vez. Podemos extender a lista de uma s√≥ vez, adicionando a ela uma outra lista de tamanho nrun povoada com valores thresh. . def run_length_decode2(dest, src, nsrc, thresh, offset): i = 0 #counter source j = 0 #counter destination while i &lt; nsrc: #while we didn&#39;t read the whole file ib = src[i] # read current position i+=1 # counter go to the next position if ib == RUN: # if current position is equal to marker RUN nrun = src[i] # next position indicates number of points below thresh i+=1 j+=nrun # Full incremental dest.extend([thresh]*nrun) #Extend the resulted list in a pythonic way elif ib == ESC: # next value is literal dest.append(src[i]/2 + offset - 127.5) j+=1 ; i+=1 else: # value dest.append(ib/2 + offset - 127.5) # If there isn&#39;t a marker I&#39;ll just keep the current value j+=1 return dest . Substitu√≠mos: . while nrun &gt; 0: dest.append(thresh) di+=1 nrun-=1 . por . di+=nrun dest.extend([thresh]*nrun) . def test_no_while(blocks, debug=False): decoded = [] if debug: blocks= blocks[:1] for block in tqdm(blocks): dest = [] src = block.data[block.start:block.stop] nsrc = len(src) #block.stop - block.start thresh = block.thresh offset = block.offset decoded.append(run_length_decode2(dest, src, nsrc, thresh, offset)) return decoded . %lprun -f run_length_decode2 test_no_while(compressed_blocks, debug=True) . Timer unit: 1e-06 s Total time: 0.001333 s File: &lt;ipython-input-39-383c0e19ee61&gt; Function: run_length_decode2 at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def run_length_decode2(dest, src, nsrc, thresh, offset): 2 1 3.0 3.0 0.2 i = 0 #counter source 3 1 2.0 2.0 0.2 j = 0 #counter destination 4 133 83.0 0.6 6.2 while i &lt; nsrc: #while we didn&#39;t read the whole file 5 132 92.0 0.7 6.9 ib = src[i] # read current position 6 132 74.0 0.6 5.6 i+=1 # counter go to the next position 7 132 88.0 0.7 6.6 if ib == RUN: # if current position is equal to marker RUN 8 60 36.0 0.6 2.7 nrun = src[i] # next position indicates number of points below thresh 9 60 46.0 0.8 3.5 i+=1 10 60 39.0 0.7 2.9 j+=nrun # Full incremental 11 60 673.0 11.2 50.5 dest.extend([thresh]*nrun) #Extend the resulted list in a pythonic way 12 72 40.0 0.6 3.0 elif ib == ESC: # next value is literal 13 dest.append(src[i]/2 + offset - 127.5) 14 j+=1 ; i+=1 15 else: 16 # value 17 72 70.0 1.0 5.3 dest.append(ib/2 + offset - 127.5) # If there isn&#39;t a marker I&#39;ll just keep the current value 18 72 87.0 1.2 6.5 j+=1 19 1 0.0 0.0 0.0 return dest . Eliminando o loop while o tempo de execu√ß√£o de uma chamada cai para menos para cerca de 10% do valor anterior. Agora cerca de 25% desse tempo √© passado extendendo a lista original: linha 11 . Vamos ver como isso se traduz ao executarmos a fun√ß√£o para todos os blocos. . %%time if mem_gib &gt; 16: d = test_no_while(compressed_blocks) . CPU times: user 1min 5s, sys: 10.4 s, total: 1min 15s Wall time: 1min 15s . Passamos de mais de 6min para pouco mais de 1min, quase de 6x mais r√°pido. Parece que somente aquele loop while interno era bastante oneroso. . del d ; gc.collect() . 131 . Trocar de Listas para arrays pr&#233;-alocados . A maioria do tempo dispendido na fun√ß√£o anterior ainda √© na extens√£o da lista original com a lista de valores threshold. . Para cada bloco a lista √© extendida com uma sublista povoada com os valores de limiar thresh. Isso demanda que a mem√≥ria seja alocada toda vez que extendemos a lista. . Nessa aloca√ß√£o os endere√ßos de mem√≥ria n√£o necessariamente est√£o adjacentes, isso certamente gera um gargalo no tempo de execu√ß√£o. . Para sanarmos isso vamos trocar a lista por um numpy array vazio, assim a mem√≥ria do array j√° √© prealocada. . def run_length_decode3(dest, src, nsrc, thresh, offset): i = 0 j = 0 while i &lt; nsrc: ib = src[i] i+=1 if ib == RUN: nrun = src[i] i+=1 dest[j:j+nrun] = thresh #dest is now a numpy array j+=nrun elif ib == ESC: # next value is literal dest[j] = src[i]/2. + offset - 127.5 j+=1 i+=1 elif j &lt; dest.shape[0]: # √Äs vezes s√£o gerados mais valores do que s√£o alocados na matriz, por algum erro na medi√ß√£o, assim os excedentes s√£o ignorados dest[j] = ib/2. + offset - 127.5 j+=1 return dest . def test_prealloc_np(blocks): decoded = np.empty((len(blocks), blocks[0].ndata), dtype=np.float16) #Essa fun√ß√£o pr√©-aloca espa√ßo na mem√≥ria sem povo√°-lo for b, block in enumerate(tqdm(blocks)): src = block.data[block.start:block.stop] nsrc = len(src) thresh = block.thresh offset = block.offset dest = np.empty(block.ndata, dtype=np.float16) decoded[b] = run_length_decode3(dest, src, nsrc, thresh, offset) return decoded . %lprun -f run_length_decode3 test_prealloc_np(compressed_blocks[:1]) . Timer unit: 1e-06 s Total time: 0.001691 s File: &lt;ipython-input-44-bd9ffa9ab792&gt; Function: run_length_decode3 at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def run_length_decode3(dest, src, nsrc, thresh, offset): 2 1 13.0 13.0 0.8 i = 0 3 1 2.0 2.0 0.1 j = 0 4 133 126.0 0.9 7.5 while i &lt; nsrc: 5 132 128.0 1.0 7.6 ib = src[i] 6 132 124.0 0.9 7.3 i+=1 7 132 134.0 1.0 7.9 if ib == RUN: 8 60 60.0 1.0 3.5 nrun = src[i] 9 60 68.0 1.1 4.0 i+=1 10 60 643.0 10.7 38.0 dest[j:j+nrun] = thresh #dest is now a numpy array 11 60 61.0 1.0 3.6 j+=nrun 12 72 69.0 1.0 4.1 elif ib == ESC: 13 # next value is literal 14 dest[j] = src[i]/2. + offset - 127.5 15 j+=1 16 i+=1 17 else: 18 # value 19 72 193.0 2.7 11.4 dest[min(j, len(dest)-1)] = ib/2. + offset - 127.5 20 72 69.0 1.0 4.1 j+=1 21 1 1.0 1.0 0.1 return dest . Vamos checar agora o desempenho com todos os blocos. . Note: Repare que prealocamos um array com tipos float16, esses ocupam 2 bytes em vez de 8. A raz√£o disso √© que os valores de n√≠vel do espectro possuem somente 1 casa decimal de precis√£o, por isso basta um float16 . %%time if mem_gib &gt; 4: d = test_prealloc_np(compressed_blocks) . CPU times: user 48.2 s, sys: 5.4 s, total: 53.6 s Wall time: 53.2 s . Sa√≠mos de cerca de 6 minutos e meio para menos de um minuto simplesmente eliminando um loop e posteriormente modificando a estrutura de dados de lista para array pr√©-alocado. Agora que temos array em vez de listas podemos visualiz√°-los melhor: . display(d[-1]) . array([-100. , -100. , -100. , ..., -147.5, -147.5, -116. ], dtype=float16) . Poder√≠amos parar por aqui se quis√©ssemos mas veremos o quanto conseguimos otimizar. . del d gc.collect() . 599 . Elimina&#231;&#227;o de Array Intermedi&#225;rio | Escrita direta na Matriz Destino . Ao iterarmos sobre os diferentes blocos b, prealocamos o array dest com um array vazio, passamos este para a fun√ß√£o run_length_decode3 e atribuimos o bloco de retorno √† linha b da matriz: . dest = np.empty(blocks[0].norig, dtype=np.float16) decoded[b] = run_length_decode3(dest, src, nsrc, thresh, offset) . Podemos em vez de prealocar o array dest podemos simplesmente passar a linha b da matriz para a fun√ß√£o e esta altera diretamente a linha da matriz de destino sem retornar nada. Isso √© poss√≠vel porque a chamada √© por refer√™ncia, isto √©, estamos passando o endere√ßo de mem√≥ria da linha b da matriz decoded e esta ir√° modificar a linha diretamente. Em python em geral todas as chamadas de fun√ß√£o s√£o assim por refer√™ncia e n√£o √© feito c√≥pias desse objeto ao pass√°-lo como argumento para fun√ß√µes. . run_length_decode4(decoded[b], src, nsrc, thresh, offset) . Os valor de thresh eoffset s√£o fixos e iguais para todos os blocos do mesmo tipo, isso √© definido no script de gera√ß√£o desses dados, ent√£o n√£o precisamos extra√≠-los toda vez, basta armazen√°-los uma √∫nica vez e repass√°-los para a fun√ß√£o. . def test_prealloc_np2(blocks): thresh = blocks[0].thresh decoded = np.empty((len(blocks), blocks[0].ndata), dtype=np.float16) offset = blocks[0].offset for b, block in enumerate(tqdm(blocks)): src = block.data[block.start:block.stop] nsrc = len(src) if b == 14014: continue run_length_decode3(decoded[b], src, nsrc, thresh, offset) return decoded . %%time if mem_gib &gt; 4: d = test_prealloc_np2(compressed_blocks) . CPU times: user 39.3 s, sys: 311 ms, total: 39.6 s Wall time: 39.3 s . print(d[-1]) . [-100. -100. -100. ... -147.5 -147.5 -116. ] . Reduzimos agora o tempo para em torno de 40s, eliminando uma cria√ß√£o e aloca√ß√£o intermedi√°ria desnecess√°ria. . Pr&#233;-Aloca&#231;&#227;o mais inteligente . Vamos revisar o que fizemos at√© o momento: . Retira os atributos thresh e offset do primeiro bloco somente, visto que s√£o iguais para todos os blocos. | Prealoca a matriz decoded com valores nulos. | Percorre os blocos, extrai os bytes de dados de cada bloco src e o comprimento desses bytes de dados nsrc | Passa esses dados e a linha referente da matriz de destino que deve ser modificada | Para cada byte de dados, o algoritmo de decodifica√ß√£o somente tem 3 tipos de atribui√ß√£o poss√≠veis para nossa matriz de destino: . Caso o byte atual tenha o valor RUN=255, pega o valor armazenado no byte seguinte nrun e atribui o valor thresh para nrun bytes da matriz | Caso o byte atual tenha o valor ESC=254, atribui o valor literal do byte seguinte | Atribui o valor literal do byte caso seja distinto de RUN ou ESC . Important: O valor thresh √© fixo e √∫nico para todos os blocos, pois √© um atributo injetado no script de gera√ß√£o desses dados. Este valor m√≠nimo substitui o piso de ru√≠do real, ou seja, pode ser considerado o valor m√≠nimo dos nossos dados. Portanto podemos simplesmente prealocar nossa matriz j√° com esse valor thresh em vez de criarmos uma matriz nula onde esses valores ser√£o repetidamente atribu√≠dos. Assim eliminamos o passo 1 acima de atribui√ß√£o porque nossa matriz original j√° estar√° povoada de valores thresh. . Tip: A opera√ß√£o + offset - 127.5 constitui uma soma e subtra√ß√£o de valores fixos ent√£o pode ser reduzida a somente 1 opera√ß√£o com valor fixo, assim definimos a nova vari√°vel: MIN = offset - 127.5. Em vez de passarmos o offset para a fun√ß√£o, passamos diretamente o MIN. | def run_length_decode4(dest, src, nsrc, MIN): i = 0 j = 0 while i &lt; nsrc: ib = src[i] i+=1 if ib == RUN: nrun = src[i] # dest[j:j+nrun] = thresh # Redundante i+=1 j+=nrun elif ib == ESC: # next value is literal dest[j] = src[i]/2. + MIN i+=1 ; j+=1 elif j &lt; dest.shape[0]: # √Äs vezes s√£o gerados mais valores do que s√£o alocados na matriz, por algum erro na medi√ß√£o, assim os excedentes s√£o ignorados: # value dest[j] = ib/2. + MIN j+=1 . def test_prealloc_np3(blocks): thresh = blocks[0].thresh decoded = np.full((len(blocks), blocks[0].ndata), thresh, dtype=np.float16) #prealocamos a matrix com os valores de limiar thresh offset = blocks[0].offset MIN = offset - 127.5 for b, block in enumerate(tqdm(blocks)): src = block.data[block.start:block.stop] nsrc = len(src) run_length_decode4(decoded[b], src, nsrc, MIN) return decoded . %lprun -f run_length_decode5 test_prealloc_np3(compressed_blocks[:1]) . Timer unit: 1e-06 s Total time: 0.000851 s File: &lt;ipython-input-61-872b68a93601&gt; Function: run_length_decode5 at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def run_length_decode5(dest, src, nsrc, MIN): 2 1 3.0 3.0 0.4 i = 0 3 1 1.0 1.0 0.1 j = 0 4 133 100.0 0.8 11.8 while i &lt; nsrc: 5 132 120.0 0.9 14.1 ib = src[i] 6 132 107.0 0.8 12.6 i+=1 7 132 127.0 1.0 14.9 if ib == RUN: 8 60 46.0 0.8 5.4 nrun = src[i] 9 # dest[j:j+nrun] = thresh # Redundante 10 60 46.0 0.8 5.4 i+=1 11 60 46.0 0.8 5.4 j+=nrun 12 72 61.0 0.8 7.2 elif ib == ESC: 13 # next value is literal 14 dest[j] = src[i]/2. + MIN 15 i+=1 ; j+=1 16 else: 17 # value 18 72 134.0 1.9 15.7 dest[min(j, len(dest)-1)] = ib/2. + MIN 19 72 60.0 0.8 7.1 j+=1 . del d gc.collect() . 424 . %%time if mem_gib &gt; 4: d = test_prealloc_np3(compressed_blocks) . CPU times: user 27.8 s, sys: 199 ms, total: 28 s Wall time: 27.8 s . Com uma prealoca√ß√£o mais inteligente e eliminando uma atribui√ß√£o reduzimos o tempo para menos de meio minuto. . display(d[-1]) . array([ -96.5, -96.5, -95.5, ..., -100. , -100. , -100. ], dtype=float16) . del d gc.collect() . 234 . Processamento Paralelo dos Blocos (Fail!) . Como estamos iterando os v√°rios blocos e aplicando a fun√ß√£o de decodifica√ß√£o, outra otimiza√ß√£o que v√™m em mente √© paralelizar essa chamada de fun√ß√£o. . Quando o gargalo √© leitura em disco e processamento na cpu, o paralelismo recomendado √© o por processos ( cores ) e n√£o via threads de um mesmo processo. . No entanto j√° estamos com o tempo bastante otimizado para quase 2 bilh√µes de pontos e multiprocessamento tem um &quot;overhead&quot; embutido na chamada. . Outra problem√°tica √© que a formula√ß√£o mais eficiente que fizemos, com o numpy array pr√©-alocado, n√£o pode ser utilizada da forma que est√° porque n√£o podemos distribuir o mesmo array para diferentes processos porque um processo n√£o compartilha mem√≥ria com os outros. . Ap√≥s v√°rias tentativas de usar o m√≥dulo multiprocessing mantendo o array pr√©-alocado com formula√ß√µes distintas tentando n√£o compartilhar o mesmo objeto para diferentes processos, o que ocorria era das duas uma: ou o processo simplesmente congela, provavelmente por ficar esperando algum recurso de mem√≥ria ou objeto indispon√≠vel, ou o procedimento √© executado com sucesso mas no fim das contas o array inicialmente alocado n√£o √© modificado, o que mostra que h√° sutilezas e complica√ß√µes ao tentar paralelizar manualmente opera√ß√µes em arrays. No entanto deixo o meu c√≥digo fracassado a seguir caso tenha algu√©m que desvende o mist√©rio. . external_function = &quot;&quot;&quot; def run_length_decode5(item, MIN=-147.5): RUN = 255 ESC = 254 dest, src = item nsrc = len(src) i = 0 j = 0 while i &lt; nsrc: ib = src[i] i+=1 if ib == RUN: nrun = src[i] # dest[j:j+nrun] = thresh # Redundante i+=1 j+=nrun elif ib == ESC: # next value is literal dest[j] = src[i]/2. + MIN i+=1 ; j+=1 elif j &lt; dest.shape[0]: # √Äs vezes s√£o gerados mais valores do que s√£o alocados na matriz, por algum erro na medi√ß√£o, assim os excedentes s√£o ignorados: # value dest[j] = ib/2. + MIN j+=1 &quot;&quot;&quot; Path(&#39;external_function.py&#39;).write_text(external_function) def test_parallel(blocks): from fastcore.parallel import parallel from fastcore.foundation import partialler from external_function import run_length_decode6 thresh = blocks[0].thresh # vamos separar a matriz por linhas e alocar as tuplas (linha, bloco) numa lista, # assim n√£o passamos a mesma estrutura de dados ( matriz ) para diferentes processos na hora de paralelizar # essa lista √© recortada e cada recorte vai para um processo ( core ) distinto. decoded_and_blocks = [(np.full((b.ndata, ), thresh, dtype=np.float16), b.data[b.start:b.stop]) for b in blocks] offset = blocks[0].offset MIN = offset - 127.5 function = partialler(run_length_decode5, MIN=MIN) setattr(function, &#39;__module__&#39;, run_length_decode6.__module__) # isso √© necess√°rio porque no paralelismo √© checado o atributo __module__ da fun√ß√£o a ser paralelizada parallel(function, decoded_and_blocks, n_workers=os.cpu_count(), pause=0.1) #decoded = np.concatenate(b[0] for b in decoded_and_blocks) return decoded_and_blocks . . Note: Eu defini a fun√ß√£o como string e a exportei para um m√≥dulo externo external_function, isso foi feito para evitar erros que ocorrem por vezes que tentamos paralelizar uma fun√ß√£o contida no mesmo m√≥dulo. . Descomente a c√©lula a seguir caso queira testar. . # d = test_parallel(compressed_blocks) . Reexaminando a implementa&#231;&#227;o C original . At√© o momento pegamos o algoritmo original em C, o adaptamos para python e gradualmente fomos reescrevendo-o com estruturas de dados otimizadas t√≠picas do python e numpy. Ao esgotarmos as possibilidades de otimiza√ß√£o e para evitar as armadilhas do processamento paralelo, podemos juntar os dois mundos. . Da√≠ surgiu a oportunidade de aprender um pouco de Cython, onde em vez escrevermos c√≥digo C puro simplesmente escrevemos o c√≥digo em python e deixamos o Cython compil√°-lo para n√≥s. . Primeiramente vamos extrair todas os elementos fixos dos blocos: . A implementa√ß√£o em cython mais eficiente que cheguei √© mostrada a seguir: . %load_ext cython . %%cython --annotate cimport cython import numpy as np cimport numpy as np #necess√°rio para usar o numpy com o Cython ctypedef np.float32_t DTYPE_t # Defino um tipo num√©rico em C, a ser utilizado no vetor a ser retornado. @cython.boundscheck(False) @cython.wraparound(False) cpdef np.ndarray[DTYPE_t, ndim=2] cy_decode_blocks(list data, int rows, int cols, int thresh, float MIN): cdef np.ndarray[DTYPE_t, ndim=2] decoded = np.full((rows, cols), thresh, np.float32) cdef const unsigned char[:] src cdef int RUN = 255 cdef int ESC = 254 cdef int NRSC cdef int i cdef int j cdef int ib cdef int nrun cdef Py_ssize_t row for row in range(rows): src = data[row] nsrc = len(src) i = 0 j = 0 while i &lt; nsrc: ib = src[i] i+=1 if ib == RUN: nrun = src[i] i+=1 j+=nrun elif ib == ESC: # next value is literal decoded[row, j] = MIN + src[i]/2. i+=1 ; j+=1 else: # value decoded[row, j] = MIN + ib/2. j+=1 return decoded . . Acima temos o resultado do c√≥digo compilado. Linhas em branco s√£o basicamente c√≥digo compilado para C puro, com a mesma efici√™ncia. Tons de amarelo indicam intera√ß√£o do compilador C com objetos python, quanto mais amarelo maior a intera√ß√£o. . Vemos que temos basicamente intera√ß√£o ao acessar objetos python: . Importa√ß√£o das bibliotecas . . Necessariamente temos que interagir para importar as bibliotecas python e suas fun√ß√µes que iremos utilizar . | Cria√ß√£o de fun√ß√£o . . N√≥s declaramos que a fun√ß√£o ir√° retornar um np.ndarray[DTYPE_t, ndim=2], isto √© um numpy array com 2 dimens√µes contendo dados do tipo DTYPE_t, esta vari√°vel definimos logo acima: ctypedef np.float32_t DTYPE_t, que nada mais √© que n√∫meros do tipo float32, o _t √© uma sintaxe espec√≠fica para indicar o tipo float32 do numpy &quot;compilado&quot; para cython, precisamos chamar ctypedef para definir vari√°veis &quot;compiladas&quot;. | Na assinatura da fun√ß√£o declaramos todos os tipos dos argumentos, os tipos s√£o os pr√≥prios do python, que ser√£o transformados em tipos C ao serem compilados. | Definimos a fun√ß√£o com a chamada cpdef, com essa chamada n√£o s√≥ compilamos nossa fun√ß√£o como ela tamb√©m fica dispon√≠vel para importa√ß√£o como objeto python. Caso quis√©ssemos somente compilar uma fun√ß√£o ou objeto e n√£o import√°-lo como objeto python, utilizamos cdef | . Recebemos objetos python na fun√ß√£o, ent√£o necessariamente h√° intera√ß√£o porque esses objetos s√£o externos ao nosso c√≥digo que ser√° compilado . | Declara√ß√£o do array que ser√° preenchido e retornado . . Aqui utilizamos nossos objetos python: rows, cols, thresh e criamos um numpy array, aqui invariavelmente tamb√©m h√° intera√ß√£o com objetos python . | Acesso aos bytes de espectro . . Mesmo caso anterior, estamos acessando os bytes armazenados no objeto data . | Retorno do array . . Aqui temos uma intera√ß√£o leve ( amarelo mais claro ) porque temos que retornar o array que foi preenchido pelo nosso c√≥digo em C de volta para um numpy array em python . Todos as demais vari√°veis dentro da fun√ß√£o, al√©m dos loops, √© compilado para um c√≥digo em C sem qualquer intera√ß√£o com o python e por isso √© muito r√°pido. Conseguimos essa fa√ßanha bastando basicamente declarar os tipos de todas as vari√°veis e assim o cython faz sua m√°gica. . Vamos ver como desempenhamos: . | . %%time # dados fixos offset = compressed_blocks[0].offset MIN = offset - 127.5 cols = compressed_blocks[0].ndata thresh = compressed_blocks[0].thresh rows = len(compressed_blocks) data_blocks = [b.data[b.start:b.stop] for b in compressed_blocks] # colocar os dados de espectro diretamente numa lista d = cy_decode_blocks(data_blocks, rows, cols, thresh, MIN) . CPU times: user 2.04 s, sys: 1.82 s, total: 3.86 s Wall time: 3.85 s . Menos de 4s para processar quase 2 bilh√µes de pontos flutantes! ü§Ø . E agora nossos blocos em si s√£o classes Python com diversos atributos, sendo um deles, .data nossos dados de espectro em bytes, assim primeiramente extraimos os bytes e n√£o utilizamos diretamente a classe Python. O motivo disso √© que para usarmos a efici√™ncia do compilador em C nossas estruturas de dados precisam ser as mais simples poss√≠veis, de prefer√™ncia tipos nativos, assim o c√≥digo em C n√£o precisa intercambiar com o python tornando-o lento. . print(d[5000]) . [ -96.5 -96.5 -95.5 ... -100. -100. -100. ] . print(d.shape) . (133932, 14848) . Um detalhe √© que n√£o utilizamos np.float16 como nas implementa√ß√µes anteriores porque n√£o existe float16 nativamente em C, assim n√£o poder√≠amos declarar um tipo de array &quot;compilado&quot; em C e a cada leitura e escrita do array ter√≠amos que interagir com o objeto python, tornando a execu√ß√£o muito mais lenta. . Espero ter ati√ßado um pouco mais a sua curiosidade sobre o Cython caso ainda n√£o o conhe√ßa, e mostrado que n√£o √© um bicho de sete cabe√ßas e √© poss√≠vel ter efici√™ncia de C ( ou quase ) no seu c√≥digo python modificando muito pouco. Esse foi mais um exerc√≠cio explorat√≥rio motivado pela curiosidade de quanto eu conseguiria otimizar a leitura de uma estrutura de dados que era importante pra mim, por ter dedicado muitas horas nela por conta do meu trabalho, fiquei feliz pelos resultados e acabei aprendendo muita coisa por conta dele. . Caso voc√™ tenha milagrosamente chegado at√© esse ponto o meu b√¥nus pra voc√™ √© que voc√™ pode ignorar tudo isso porque j√° fizeram de maneira infinitamente melhor pra voc√™: A biblioteca Numba √© um compilador just-in-time para Python que funciona melhor em c√≥digo que usa matrizes e fun√ß√µes NumPy e loops. Ele n√£o s√≥ compila como paraleliza seu c√≥digo em todos os cores da CPU ou da GPU caso voc√™ tiver. .",
            "url": "https://ronaldo.tech/spectrum%20monitoring/profiling/numpy/cython/2021/09/20/Leitura_de_Dados_Bin%C3%A1rios_Comprimidos_Otimiza%C3%A7%C3%A3o_Gradual_em_Python.html",
            "relUrl": "/spectrum%20monitoring/profiling/numpy/cython/2021/09/20/Leitura_de_Dados_Bin%C3%A1rios_Comprimidos_Otimiza%C3%A7%C3%A3o_Gradual_em_Python.html",
            "date": " ‚Ä¢ Sep 20, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Tensores e Multiplica√ß√£o de Matrizes",
            "content": ". Um escalar ( n√∫mero ), um vetor, uma matriz ou qualquer estrutura n-dimensional s√£o simplesmente tensores de diferentes ordens. Um escalar √© um tensor de ordem (ou dimens√£o) 0, um vetor √© um tensor de ordem 1, uma matriz √© um tensor de ordem 2. Uma matriz &quot;c√∫bica&quot; √© um tensor de ordem 3 e assim por diante.Desse modo daqui em diante nos referimos a tudo simplesmente como &quot;tensores&quot;, sejam eles vetores, matrizes ou objetos de dimens√£o superior. . Vamos importar as depend√™ncias necess√°rias, pytorch e numpy. . . Tip: Utilize o link acima Open in Colab para explorar e editar o c√≥digo dessa postagem direto do Navegador. Nele todas as depend√™ncias j√° est√£o instalada. N√£o se preocupe de instalar e configurar bibliotecas num primeiro momento. . import torch import numpy as np . Criando alguns tensores b&#225;sicos . Para criar um escalar, basta fornecer um n√∫mero ao construtor. . escalar = torch.tensor(5) escalar . tensor(5) . escalar.dtype . torch.int64 . No entanto o uso de tensores de tipo inteiro √© limitado, o padr√£o √© criarmos tensores do tipo ponto flutuante ( float ). . escalar = torch.tensor(5.) escalar . tensor(5.) . escalar.dtype . torch.float32 . 5. √© uma abrevia√ß√£o de 5.0. . Para checarmos a dimens√£o do tensor, usamos o m√©todo dim . escalar.dim() . 0 . Se quisermos recuperar o tensor escalar como um n√∫mero python, usamos o m√©todo item, este met√≥do tamb√©m √© v√°lido para tensores n√£o escalares que cont√©m somente 1 elemento: . escalar.item() . 5.0 . x = torch.tensor([[2.]]) x.item() . 2.0 . x = torch.randn(3, 3) ; x . tensor([[ 1.2155, -0.4055, 0.3777], [-0.1294, 1.0666, 0.4260], [ 1.1780, -1.4406, 0.1562]]) . Para criarmos um vetor, basta fornecermos qualquer objeto iter√°vel do python, como lista, tuplas, range, etc... . vetor = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) vetor . tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) . . Important: Uma restri√ß√£o importante √© que os dados de um tensor devem ter tipo √∫nico, n√£o podemos ter um tensor com inteiros, floats e booleanos por exemplo . vetor = torch.tensor([0., 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) vetor . tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11.]) . No caso acima fornecemos somente o primeiro n√∫mero como float: 0. e o Pytorch converteu todos os demais para o tipo float . vetor = torch.tensor([x for x in range(12)]) vetor . tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) . vetor = torch.tensor(range(12)) vetor . tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) . Para checar a dimens√£o do tensor, poder utilizar o atributo shape ou o m√©todo size . vetor.shape . torch.Size([12]) . vetor.size() . torch.Size([12]) . print(f&#39;Dimens√£o do Vetor: {vetor.dim()}&#39;) . Dimens√£o do Vetor: 1 . Pytorch √© fortemente integrado com o numpy, inclusive empresta muito da API utilizada por este. Se voc√™ possui alguma familiaridade com numpy facilmente consegue compreender e escrever c√≥digo em Pytorch. . Criamos um array com numpy . array = np.array([[0., 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]) array . array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]) . Para transformarmos em tensor, existem v√°rias formas como passar o array diretamente ao construtor torch.tensor, no entanto o construtor cria um c√≥pia do array original. Outros m√©todos como: torch.from_numpy e torch.as_tensor compartilham a mem√≥ria e a modifica√ß√£o efetuada em 1 √© refletida no outro. . matrix = torch.from_numpy(array) matrix . tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]], dtype=torch.float64) . matrix[0,0] = -1 . array . array([[-1., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]) . . Note: Para acessar os elementos de um tensor, √© usada a mesma indexa√ß√£o j√° conhecida de objetos python e numpy arrays . Se quisermos recuperar o array novamente, temos o m√©todo numpy . matrix.numpy() . array([[-1., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]) . Mudando o formato de um tensor . Frequentemente temos que adaptar o formato dos tensores para efetuar diversas opera√ß√µes, isso √© feito com o m√©todo reshape. Vamos transformar o tensor unidimensional anteriormente definido com 12 elementos em diferentes formatos. Isso √© poss√≠vel desde que o resultado contenha o mesmo n√∫mero de elementos. . vetor = vetor.reshape(3,4) vetor . tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) . vetor.shape . torch.Size([3, 4]) . vetor.dim() . 2 . Se n√£o informarmos 1 dimens√£o e colocarmos -1 em seu lugar, o Pytorch infere a quantidade de elementos das demais. . vetor = vetor.reshape(3,-1) vetor . tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) . vetor.reshape(-1, 4) . tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) . vetor = vetor.reshape(-1, 2, 2) vetor . tensor([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]], [[ 8, 9], [10, 11]]]) . vetor.shape . torch.Size([3, 2, 2]) . vetor.dim() . 3 . Se informarmos uma quantidade de elementos divergentes √© retornado um RuntimeError . vetor.reshape(3, 4, 4) . RuntimeError Traceback (most recent call last) &lt;ipython-input-31-49750a02386c&gt; in &lt;module&gt; -&gt; 1 vetor.reshape(3, 4, 4) RuntimeError: shape &#39;[3, 4, 4]&#39; is invalid for input of size 12 . Normalmente criamos dados √† partir de algum dado armazenado, por exemplo uma imagem √© um tensor com 3 dimens√µes: Linhas x Colunas x Cores. No entanto para v√°rios tensores comumente utilizados, existe diversos m√©todos do Pytorch que possibilita a cria√ß√£o autom√°tica deles. Vejamos alguns: . Tensor Nulo . torch.zeros((3,4)) . tensor([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) . Tensor Unit√°rio . torch.ones(3, 4) . tensor([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) . Tensor Identidade . torch.eye(3,3) . tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) . Tensor com valores amostrados de alguma distribui√ß√£o . t1 = torch.randn((3,4)) ; t1 . tensor([[ 0.6482, -1.2590, 1.1658, 0.9287], [-1.2208, 0.8042, 1.0299, 0.2370], [-1.4051, 0.1101, -0.3225, 0.1291]]) . Como a distribui√ß√£o normal com m√©dia 0 e desvio padr√£o 1 e t√£o comum existe esse m√©todo para cri√°-la rapidamente somente fornecendo as dimens√µes desejadas. . t1.mean() . tensor(0.0705) . t1.std() . tensor(0.9307) . Para outros valores de m√©dia e desvio padr√£o utilize: . x = torch.normal(2,4, (3,4)) . x.mean() . tensor(1.2909) . x.std() . tensor(3.7982) . Para outras distribui√ß√µes consulte a documenta√ß√£o do Pytorch. . Empilhar Tensores . √â comum precisarmos combinar diferentes tensores ao longo de algum eixo. Isso normalmente significa criarmos uma dimens√£o adicional e mantermos as demais dimens√µes. Sejam 2 tensores 3x4: . x = torch.arange(12).reshape(3,4).float() y = torch.Tensor([[2,1,4,3], [1,2,3,4], [4,3,2,1]]).float() . x,y . (tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]), tensor([[2., 1., 4., 3.], [1., 2., 3., 4.], [4., 3., 2., 1.]])) . Vamos empilh√°-los √† partir da primeira dimens√£o . z = torch.stack([x,y], dim=0) ; z . tensor([[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]], [[ 2., 1., 4., 3.], [ 1., 2., 3., 4.], [ 4., 3., 2., 1.]]]) . z.shape . torch.Size([2, 3, 4]) . Vemos que foi criada uma dimens√£o adicional e colocado no in√≠cio, dado o par√¢metro dim=0. Caso quis√©ssemos empilhar os tensores numa dimens√£o distinta. . z = torch.stack([x,y], dim=1) ; z . tensor([[[ 0., 1., 2., 3.], [ 2., 1., 4., 3.]], [[ 4., 5., 6., 7.], [ 1., 2., 3., 4.]], [[ 8., 9., 10., 11.], [ 4., 3., 2., 1.]]]) . z.shape . torch.Size([3, 2, 4]) . z = torch.stack([x,y], dim=2) ; z . tensor([[[ 0., 2.], [ 1., 1.], [ 2., 4.], [ 3., 3.]], [[ 4., 1.], [ 5., 2.], [ 6., 3.], [ 7., 4.]], [[ 8., 4.], [ 9., 3.], [10., 2.], [11., 1.]]]) . z.shape . torch.Size([3, 4, 2]) . Criar tensores booleanos &#224; partir de compara&#231;&#245;es . Ao compararmos dois tensores distintos, o resultado √© um tensor de mesma dimens√£o cujos elementos s√£o os valores booleanos (Verdadeiro ou Falso) da compara√ß√£o termo a termo . z = x == y z . tensor([[False, True, False, True], [False, False, False, False], [False, False, False, False]]) . Como em python, ao tentarmos fazer opera√ß√µes num√©ricas com valores booleanos, temos True == 1 e False == 0. Assim ao somarmos os valores do tensor acima temos o resultado 2. . z.sum() . tensor(2) . Opera&#231;&#245;es Elemento a Elemento . As seguintes opera√ß√µes em tensores s√£o efetuadas elemento a elemento, isto √©, a opera√ß√£o tem como resultado um tensor da mesma forma, por√©m com a opera√ß√£o efetuada nos elementos de mesmo √≠ndice. Isso normalmente exige que os tensores tenham dimens√µes iguais. . x = torch.Tensor([1,2,4,8]) y = torch.Tensor([2,2,2,2]) . Adi√ß√£o . x+y . tensor([ 3., 4., 6., 10.]) . Subtra√ß√£o . x-y . tensor([-1., 0., 2., 6.]) . Multiplica√ß√£o (Elemento a Elemento) . Warning: N√£o confunda com a multiplica√ß√£o matricial, esta retorna uma matriz. . x*y . tensor([ 2., 4., 8., 16.]) . Exponencial . x**y . tensor([ 1., 4., 16., 64.]) . Broadcasting . Uma tradu√ß√£o livre para o termo Broadcasting √© transmiss√£o. Broadcasting ocorre quando tentamos realizar algumas opera√ß√µes aritm√©ticas, como as opera√ß√µes elemento a elemento vistas no par√°grafo anterior, em tensores com dimens√µes distintas. Se a opera√ß√£o suporta broadcasting e a dimens√£o dos tensores s√£o compat√≠veis com algumas regras, essas dimens√µes s√£o automaticamente expandidas, i.e. os valores das dimens√µes menores s√£o transmitidos para as dimens√µes expandidas sem que haja c√≥pia desnecess√°ria dos mesmos. . As duas regras sem√¢nticas b√°sicas que devem ser obedecidas pelos tensores para que seja poss√≠vel o broadcasting s√£o: . Cada tensor precisa ter ao menos 1 dimens√£o | Ao alinharmos as dimens√µes de ambos tensores elas precisam obedecer um dos casos: Serem iguais | Uma delas possuir o valor 1 | Uma delas n√£o existir | | Isso fica mais claro com alguns exemplos. . O caso mais simples de broadcasting √© ao multiplicarmos um escalar a um tensor.Seja o exemplo de multiplica√ß√£o de tensores elemento a elemento: . a = torch.tensor([1., 2, 3]) b = torch.tensor([2., 2, 2]) a * b . tensor([2., 4., 6.]) . Podemos obter o mesmo resultado multiplicando por um escalar . b = 2.0 a * b . tensor([2., 4., 6.]) . O resultado √© o mesmo da opera√ß√£o anterior, foi realizado o broadcasting. Vamos checar as regras: . Num primeiro momento parece que violamos a regra 1, porque mesmo um n√∫mero sendo promovido a um tensor escalar, este por defini√ß√£o possui dimens√£o nula. No entanto neste caso o escalar √© equivalente a um vetor com um √∫nico elemento. Assim a regra n√£o √© violada e podemos considerar o escalar como um vetor linha - 1x1 | Quanto √† regra 2: 2ii: Ao alinharmos as colunas do tensor b com o tensor a: A 1¬™ coluna em b possui a dimens√£o 1 | 2iii: Para as colunas 2 e 3 de a as colunas em b n√£o existem | . | Assim ao percorrermos as dimens√µes de ambos tensores todas as regras do broadcasting s√£o obedecidas. N√£o se preocupe em decorar essas regras. Isso foi somente para ilustrar, com alguma pr√°tica isso se torna autom√°tico. . Conceitualmente o vetor √© esticado de 1 para 3 colunas e o valor da coluna 1 em b √© transmitido para as outras duas colunas, da√≠ o termo broadcasting | Isso √© conceitual somente porque o valor n√£o √© duplicado pelo Pytorch, inclusive √© mais eficiente quanto √† mem√≥ria do que a opera√ß√£o anterior porque um escalar ocupa menos espa√ßo que um vetor. | . . Um segundo exemplo com uma matriz ( 2 dimens√µes ) e um vetor ( 1 dimens√£o ) . a = torch.tensor([[ 0.0, 0.0, 0.0], [10.0, 10.0, 10.0], [20.0, 20.0, 20.0], [30.0, 30.0, 30.0]]) b = torch.tensor([1.0, 2.0, 3.0]) a + b . tensor([[ 1., 2., 3.], [11., 12., 13.], [21., 22., 23.], [31., 32., 33.]]) . Nesse caso temos as dimens√µes a:4x3 e b:1x3: Ao percorrermos as dimens√µes de ambos temos . A segunda dimens√£o √© igual a 3: 2i | A primeira dimens√£o de um dos tensores √© 1: 2ii | . Assim a √∫nica linha do vetor b √© replicada outras 3 vezes para que o resultado tenha as mesmas dimens√£o da matriz a . . O broadcasting em v√°rios casos n√£o √© intuitivo, esses foram dois exemplos super simples e somente a utiliza√ß√£o constante e botar a m√£o na massa com v√°rios exemplos √© que torna o conceito um pouco mais claro. Consulte esse link a seguir para um tutorial detalhado sobre broadcasting . Multiplica&#231;&#227;o de Matrizes . A defini√ß√£o de Multiplica√ß√£o de 2 matrizes A e B √©: . A f√≥rmula para cada termo da matriz produto C √©: $$C_{ij} = sum_kA_{ik}B_{kj}$$ . Em c√≥digo no geral √© mais f√°cil visualizar, vamos criar 2 matrizes de tamanho razo√°vel para analisarmos a efici√™ncia dos c√°lculos: . a = torch.randn(56, 112) b = torch.randn(112, 56) . a_linhas, a_colunas = a.shape b_linhas, b_colunas = b.shape . Para que seja poss√≠vel multiplicar ambas as matrizes precisamos que o n√∫mero de colunas da matriz a deve ser igual ao n√∫mero de linhas da coluna b. . a_colunas == b_linhas . True . Vamos inicialmente criar o vetor produto vazio: . c = torch.zeros(a_linhas, b_colunas) . Na defini√ß√£o b√°sica da multiplica√ß√£o de matriz temos 3 loops: . for i in range(a_linhas): for j in range(b_colunas): for k in range(a_colunas): # ou b_linhas c[i,j] += a[i,k] * b[k,j] . Vamos colocar a defini√ß√£o acima numa fun√ß√£o, assim n√£o repetimos c√≥digo, podemos reutiliz√°-lo e mensurar o tempo m√©dio de execu√ß√£o . def matmul(a:torch.Tensor,b:torch.Tensor)-&gt; torch.Tensor: &quot;Retorna a matrix produto entre a e b&quot; # Dimens√µes a_linhas, a_cols = a.shape b_linhas, b_cols = b.shape # Verifica√ß√£o de Compatibilidade assert a_cols==b_linhas, &quot;O n√∫mero de colunas da matriz {a_cols} deve ser igual a {b_linhas}&quot; c = torch.zeros(a_linhas, b_cols) for i in range(a_linhas): for j in range(b_cols): for k in range(a_cols): # ou b_linhas c[i,j] += a[i,k] * b[k,j] return c . Vamos calcular quanto tempo leva esse c√°lculo utilizando a defini√ß√£o b√°sica com 3 loops. . %time c=matmul(a, b) . CPU times: user 13.4 s, sys: 0 ns, total: 13.4 s Wall time: 13.4 s . Vemos que essas matrizes, muito pequenas para os par√¢metros modermos de Deep Learning, o c√°lculo j√° leva um tempo enorme, o que a torna insustent√°vel. Na pr√°tica os &quot;loops&quot; s√£o eliminados, e m√©todos eficientes de &quot;vetoriza√ß√£o&quot; s√£o utilizados. Vamos testar como podemos otimizar o c√≥digo somente utilizando o broadcasting visto . Podemos eliminar o √≠ndice k, usando a multiplica√ß√£o elemento a elemento, no lugar do √≠ndice k colocamos :, o que significa aplicarmos em todo eixo referenciado. A seguir utilizamos o m√©todo sum no eixo. Isso resulta na mesma opera√ß√£o efetuada anteriormente com o loop em k . def matmul(a:torch.Tensor,b:torch.Tensor)-&gt; torch.Tensor: &quot;Retorna a matrix produto entre a e b&quot; # Dimens√µes a_linhas, a_cols = a.shape b_linhas, b_cols = b.shape # Verifica√ß√£o de Compatibilidade assert a_cols==b_linhas, &quot;O n√∫mero de colunas da matriz {a_cols} deve ser igual a {b_linhas}&quot; c = torch.zeros(a_linhas, b_cols) for i in range(a_linhas): for j in range(b_cols): c[i,j] = (a[i,:] * b[:,j]).sum() return c . %time c=matmul(a, b) . CPU times: user 137 ms, sys: 139 ¬µs, total: 137 ms Wall time: 136 ms . Podemos otimizar mais e eliminar o loop no √≠ndice j. No entanto n√£o podemos simplesmente elimin√°-lo, porque sen√£o viola as regras acima de broadcasting, seja por exemplo o √≠ndice i=0 e j=0: . a[0, :] * b . RuntimeError Traceback (most recent call last) &lt;ipython-input-67-c7015e3e45b9&gt; in &lt;module&gt; -&gt; 1 a[0, :] * b RuntimeError: The size of tensor a (112) must match the size of tensor b (56) at non-singleton dimension 1 . a[0, :].shape . torch.Size([112]) . b.shape . torch.Size([112, 56]) . O vetor a indexado possui somente uma dimens√£o com 4 elementos e b possui 2 dimens√µes no formato 4x3. Para nos adequar √†s regras de broadcasting temos que criar um eixo adicional para assim atender √† regra 2i: . Para tal podemos indexar o eixo adicional com o valor especial None ou usar o m√©todo unsqueeze() . a[0, :, None].shape . torch.Size([112, 1]) . a[0].unsqueeze(-1).shape . torch.Size([112, 1]) . def matmul(a:torch.Tensor,b:torch.Tensor)-&gt; torch.Tensor: &quot;Retorna a matrix produto entre a e b&quot; # Dimens√µes a_linhas, a_cols = a.shape b_linhas, b_cols = b.shape # Verifica√ß√£o de Compatibilidade assert a_cols==b_linhas c = torch.zeros(a_linhas, b_cols) for i in range(a_linhas): c[i] = (a[i].unsqueeze(-1) * b).sum(dim=0) return c . %time c=matmul(a, b) . CPU times: user 3.98 ms, sys: 0 ns, total: 3.98 ms Wall time: 3.5 ms . Mas isso foi somente para ilustrar os conceitos, na pr√°tica usamos a Implementa√ß√£o Otimizada do Pytorch em C++ . %time c= a.matmul(b) . CPU times: user 168 ¬µs, sys: 3.9 ms, total: 4.07 ms Wall time: 3.39 ms . Um m√©todo equivalente √© usar o operador @ . %time c= a@b . CPU times: user 143 ¬µs, sys: 5 ¬µs, total: 148 ¬µs Wall time: 154 ¬µs . Isso foi somente uma pincelada super b√°sica sobre tensores e alguns conceitos e opera√ß√µes b√°sicas sobre eles e uma ilustra√ß√£o em como implementar multiplica√ß√£o de matrizes de forma b√°sica e mais otimizada para ilustrar tais conceitos. Por fim simplesmente utilizamos a implementa√ß√£o nativa do Pytorch quando formos de fato utilizar tais opera√ß√µes .",
            "url": "https://ronaldo.tech/pytorch/basics/2020/05/23/Tensores.html",
            "relUrl": "/pytorch/basics/2020/05/23/Tensores.html",
            "date": " ‚Ä¢ May 23, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Sobre mim",
          "content": "Meu nome √© Ronaldo S.A. Batista, pai da Melinda, marido da Priscila. Formei-me em Ci√™ncias Moleculares na USP, mas as tribula√ß√µes da vida me impediram de seguir o plano de ser um acad√™mico multidisciplinar. Desde ent√£o atuo como fiscal de servi√ßos p√∫blicos na ANATEL, especificamente no monitoramento do espectro de radiofrequ√™ncia. Al√©m das tarefas de monitoramente implemento solu√ß√µes de an√°lises de dados em python . Sou muito grato por tudo que essa posi√ß√£o me proveu e continua provendo. . No entanto, nunca abandonei o estudo de F√≠sica, Matem√°tica e Programa√ß√£o, em vez disso os tornei um hobby. . Programar √© mais um hobby que trabalho, dado a oportunidade rara de criar algo. . Sempre fui vidrado em como criar melhores h√°bitos e qual a melhor maneira de atingir nossos objetivos, por que a vida √© curta e se pudermos torn√°-la mais eficiente vale a tentativa. . Esse blog √© uma tentativa de criar o h√°bito de escrever e consolidar o conhecimento, se for √∫til para uma pessoa sequer j√° √© um b√¥nus. .",
          "url": "https://ronaldo.tech/_pages/about.html",
          "relUrl": "/_pages/about.html",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://ronaldo.tech/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}